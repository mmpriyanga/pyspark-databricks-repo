{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "488e74a0-4658-43d1-a420-8b23a781e0ae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Task 1: \n",
    "- Document the Notebook Using mark down \"%md\" \n",
    "- A good Title \n",
    "- Description of the task \n",
    "- Your name in some color\n",
    "- Bring our Team photo from the given url \"https://fpimages.withfloats.com/actual/6929d1ac956d0a744b5c9822.jpeg\" \n",
    "Use headings, bold, italics appropriately.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7a242ce8-681b-45d4-baa1-b98d3e293679",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Databricks Magic Commands & Markdown\n",
    "This task covers the fundamentals of using magic commands and Markdown in Databricks notebooks. You will learn how to execute system-level commands, switch between different languages (Python, SQL, R, Scala), and format notebook documentation using Markdown for improved readability and collaboration.\n",
    "\n",
    "<font color=\"red\">**_PRIYANGA MARANAYANAR_**</font>\n",
    "\n",
    "![](https://www.databricks.com/sites/default/files/2023-11/databricks-og-universal.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6eb51bc0-c883-4a2c-9bda-0f0faab61cea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 2:\n",
    "Create a volume namely usage_metrics using sql magic command %sql"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4cfa777b-7476-415a-8f8e-25434ce3a1f4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%sql\n",
    "CREATE VOLUME IF NOT EXISTS workspace.default.usage_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "40a6394e-64e0-446b-9532-dfc63d3e352e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "\n",
    "#Task 3: \n",
    "Create a child notebook \"4_child_nb_dataload\" and write code to load data, Using the requests library, perform api call to pull data from \"https://public.tableau.com/app/sample-data/mobile_os_usage.csv\" into a python variable using the magic command %py and write the data into the created volume \"/Volumes/workspace/default/usage_metrics/mobile_os_usage.csv\" using the above variable.text using the magic command dbutils.fs.put(\"volume\",variable.text,overwrite=True)\n",
    "\n",
    "#Task 4: \n",
    "Call the notebook 4_child_nb_dataload using the magic command %run\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "fe47e784-d532-4cbe-a95d-d888b1d823a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run /Workspace/Users/mmpriyanga1996@gmail.com/pyspark-databricks-repo/Excercises_And_Usecases_Inceptez/4_child_nb_dataload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9b7afd0c-d9da-4c1f-9a6c-257ad1500915",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 5: \n",
    "list the file is created in the given volume or not and do the head of this file using fs magic command %fs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "eb979557-8b51-461d-a808-01e6d3540bdc",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs ls \"/Volumes/workspace/default/usage_metrics\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "825dfbfc-a731-4cba-abac-064494815167",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%fs head dbfs:/Volumes/workspace/default/usage_metrics/mobile_os_usage.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57e87c24-6867-42a6-ad39-caa6d87e3906",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 6: \n",
    "Create a pyspark dataframe df1 reading the data from the above file using pyspark magic command %python\n",
    "\n",
    "#Task 7:\n",
    "Write the above dataframe df1 data into a databricks table called 'default.mobile_os_usage' using pyspark magic command %python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "88cffe4a-404d-4761-9085-5dc4103c1af6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.session import SparkSession\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "#print(spark)\n",
    "df = spark.read.csv(\"dbfs:/Volumes/workspace/default/usage_metrics/mobile_os_usage.csv\",header = True)\n",
    "display(df)\n",
    "# Clean column names: replace invalid characters with underscore\n",
    "clean_df = df.toDF(\n",
    "    *[c.replace(\" \", \"_\")\n",
    "       .replace(\"(\", \"\")\n",
    "       .replace(\")\", \"\")\n",
    "       .replace(\"%\", \"\")\n",
    "       .replace(\",\", \"_\")\n",
    "       .replace(\";\", \"_\")\n",
    "       .replace(\"=\", \"_\")\n",
    "       for c in df.columns]\n",
    ")\n",
    "\n",
    "clean_df.write.saveAsTable(\"default.mobile_os_usage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "33157950-c5e1-4cb7-8f4b-07b343360dae",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 8:\n",
    "Write sql query to display the data loaded into the table 'default.mobile_os_usage' using the pyspark magic command %python \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ffb5b34e-1b35-4841-9c8d-c74cbc6df3c2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "\n",
    "select * from default.mobile_os_usage limit 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7c156022-ce94-4d55-8343-8a56abf29aa2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "df = spark.read.table(\"default.mobile_os_usage\")\n",
    "df = df.withColumn(\"Mobile_Operating_System\", F.upper(\"Mobile_Operating_System\"))\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "74c580eb-1314-4098-96f3-289bc8d6f8a0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 9:\n",
    "Create a python function to convert the given input to upper case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f81ccd0f-37f7-47bd-9255-6762f3909ed5",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "inp = input(\"Enter a string: \")\n",
    "def convert_uppercase(inp):\n",
    "    inp = inp.upper()\n",
    "    print(inp)\n",
    "convert_uppercase(inp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7703211c-ad34-4b2e-92f7-16bca208f3ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 10: \n",
    "Install pandas library using the pip python magic command %pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "9f6a3580-8ec5-400b-beac-579b894ea77c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "%pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "dba3ff38-d50f-4d80-9bef-5878b3f751f2",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 11: \n",
    "Import pandas, using pandas read_csv and display the output using the magic command %python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c542d402-64c0-46dd-8d70-6a866af9bc32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%python\n",
    "import pandas as pd\n",
    "data = pd.read_csv(\"/Volumes/workspace/default/usage_metrics/mobile_os_usage.csv\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "7f312639-ee7f-485b-bda2-2c68c78cb426",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Task 12: \n",
    "echo \"Magic commands tasks completed\" using the linux shell magic command %sh "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5d619c45-6d0d-493c-87b5-4daa092addcd",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sh\n",
    "echo \"Magic commands tasks completed\""
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": {
    "hardware": {
     "accelerator": null,
     "gpuPoolId": null,
     "memory": null
    }
   },
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 8724633705563775,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "explore_notebooks_and_magic_commands",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
