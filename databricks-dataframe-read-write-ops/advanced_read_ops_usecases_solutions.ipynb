{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2f5a9515-8a37-4306-9e98-213dbe7d0b3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###1. Options for handling quotes & Escape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "754be2b4-ce52-43be-bf74-8b460a4a53d9",
     "showTitle": false,
     "tableResultSettingsMap": {
      "0": {
       "dataGridStateBlob": "{\"version\":1,\"tableState\":{\"columnPinning\":{\"left\":[\"#row_number#\"],\"right\":[]},\"columnSizing\":{\"stdCost\":135},\"columnVisibility\":{}},\"settings\":{\"columns\":{}},\"syncTimestamp\":1766159898916}",
       "filterBlob": null,
       "queryPlanFiltersBlob": null,
       "tableResultIndex": 0
      }
     },
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import (\n",
    "    StructType, StructField,\n",
    "    IntegerType, StringType,\n",
    "    DecimalType, TimestampType, DateType, FloatType\n",
    ")\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"productId\", StringType(), True),\n",
    "    StructField(\"productName\", StringType(), True),\n",
    "    StructField(\"prodCost\", FloatType(), True),\n",
    "    StructField(\"prodPrice\", FloatType(), True),\n",
    "    StructField(\"effective_timestamp\", TimestampType(), True),\n",
    "    StructField(\"effective_date\", DateType(), True),\n",
    "    StructField(\"corruptRecord\", StringType(), True)\n",
    "])\n",
    "\n",
    "sales_df = spark.read.csv('/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales.csv', quote = '\"', header = True, comment = '#', escape = '~', multiLine = True, nanValue=-1, nullValue = 'na', mode = 'permissive', columnNameOfCorruptRecord = 'corruptRecord', schema = schema,ignoreLeadingWhiteSpace=True,ignoreTrailingWhiteSpace=True)\n",
    "display(sales_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ef95e0ea-3be9-426d-89e1-7a846456f8c8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "sales_df_mal = spark.read.csv('/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales_mal_formed.csv', quote = '\"', header = True, comment = '#', escape = '~', multiLine = True, nanValue=-1, nullValue = 'na', mode = 'permissive', columnNameOfCorruptRecord = 'corruptRecord', schema = schema)\n",
    "\n",
    "display(sales_df_mal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "4c98b699-8f25-4b2e-834d-53cbb32c42cf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "\n",
    "schema = StructType([\n",
    "    StructField(\"productId\", StringType(), True),\n",
    "    StructField(\"productName\", StringType(), True),\n",
    "    StructField(\"stdCost\", StringType(), True),\n",
    "    StructField(\"stdPrice\", StringType(), True),\n",
    "    StructField(\"effDt\", StringType(), True),\n",
    "    StructField(\"dt\", StringType(), True),\n",
    "    StructField(\"corruptRecord\", StringType(), True)\n",
    "])\n",
    "\n",
    "sales_df_mal = spark.read.csv(\n",
    "    \"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales_mal_formed.csv\",\n",
    "    header=True,\n",
    "    quote='\"',\n",
    "    escape='~',\n",
    "    multiLine=True,\n",
    "    comment='#',\n",
    "    mode=\"permissive\",\n",
    "    columnNameOfCorruptRecord=\"corruptRecord\",\n",
    "    schema=schema\n",
    ")\n",
    "\n",
    "display(sales_df_mal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8af5ba96-586f-4da8-a929-63befccac1f0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "struct1 = \"productId string, productName string, prodCost float, prodPrice float, effective_timestamp timestamp, effective_date date,corrupt_record string\"\n",
    "\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales_mal_formed.csv\",header=True,sep=',',mode='permissive',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote='\"', multiLine = True, escape = '~' )\n",
    "display(df1)\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales_mal_formed.csv\",header=True,sep=',',mode='dropMalformed',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote='\"',multiLine = True, escape = '~' )\n",
    "display(df1)\n",
    "df1=spark.read.schema(struct1).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/malformed_cust/sales_mal_formed.csv\",header=True,sep=',',mode='failFast',comment='#',columnNameOfCorruptRecord=\"corrupt_record\",quote='\"', multiLine = True, escape = '~' )\n",
    "display(df1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e468a926-48d9-40c1-97b8-ff4dcb0955bf",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "advanced_read_ops_usecases_solutions",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
