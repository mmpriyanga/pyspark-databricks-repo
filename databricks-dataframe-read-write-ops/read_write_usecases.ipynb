{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8ba86a20-5a3a-4130-86f5-e312f4a7901b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#Telecom Domain ReadOps Assignment\n",
    "This notebook contains assignments to practice Spark read options and Databricks volumes. <br>\n",
    "Sections: Sample data creation, Catalog & Volume creation, Copying data into Volumes, Path glob/recursive reads, toDF() column renaming variants, inferSchema/header/separator experiments, and exercises.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "841c7ed8-ef18-486a-8187-07685e499b84",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "![](https://fplogoimages.withfloats.com/actual/68009c3a43430aff8a30419d.png)\n",
    "![](https://theciotimes.com/wp-content/uploads/2021/03/TELECOM1.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4aa0a44-8cd6-41cf-921d-abb5ff67615b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##First Import all required libraries & Create spark session object"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d0b67823-2e4e-45e2-aa25-80550a3ac580",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##1. Write SQL statements to create:\n",
    "1. A catalog named telecom_catalog_assign\n",
    "2. A schema landing_zone\n",
    "3. A volume landing_vol\n",
    "4. Using dbutils.fs.mkdirs, create folders:<br>\n",
    "/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/\n",
    "/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/\n",
    "/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\n",
    "5. Explain the difference between (Just google and understand why we are going for volume concept for prod ready systems):<br>\n",
    "a. Volume vs DBFS/FileStore<br>\n",
    "b. Why production teams prefer Volumes for regulated data<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "implicitDf": true,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "82ad38e6-0de4-4ea8-bcfe-3a0890990307",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%sql\n",
    "CREATE CATALOG IF NOT EXISTS telecom_catalog_assign;\n",
    "CREATE SCHEMA IF NOT EXISTS telecom_catalog_assign.landing_zone;\n",
    "CREATE VOLUME IF NOT EXISTS telecom_catalog_assign.landing_zone.landing_vol;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "26aec3ea-bd62-4fd6-8b8a-757e27a37be0",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c64c8454-1bf7-42b0-bcd8-410dbc3975bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e33a8b6f-6083-4b4d-bc19-cc8a68b41f07",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1/ericsson\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1/nokia\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region1/huawei\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2/ericsson\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2/nokia\")\n",
    "dbutils.fs.mkdirs(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/region2/huawei\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "68e213ec-a3c5-4275-86a5-e0386e8ca063",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "cust_path = \"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/\"\n",
    "usage_path = \"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/\"\n",
    "tower_path = \"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/tower/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "1f983726-a9bf-4986-a59f-fbfdedae08fe",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###DBFS (Databricks File System):\n",
    "\n",
    "DBFS is a filesystem abstraction layer used by Databricks clusters to access data stored in cloud object storage. It provides a Unix-like filesystem interface (dbfs:/) that Spark and other runtimes use to read and write files. DBFS maps filesystem operations to native cloud storage APIs and serves as the technical access layer for file operations. DBFS itself does not provide governance, fine-grained access control, or auditing. It is commonly used for legacy workloads, temporary files, and backward compatibility.\n",
    "\n",
    "###Volume:\n",
    "\n",
    "A volume is a Unity Catalog–governed object that represents a logical volume of storage in a cloud object storage location. Volumes are designed to store non-tabular data and provide governance capabilities similar to tables, including fine-grained access control, auditing, and lineage. Volumes are organized under a catalog and schema alongside tables and views. A volume can be either managed or external. Files stored in volumes are accessed using paths under /Volumes/<catalog>/<schema>/<volume>/.\n",
    "\n",
    "Although volume paths often appear as dbfs:/Volumes/..., this does not mean volumes are DBFS. DBFS is used only as the runtime filesystem interface, while Unity Catalog enforces governance, permissions, and auditing on the volume.\n",
    "\n",
    "###Key Difference:\n",
    "\n",
    "DBFS focuses on providing a filesystem interface to interact with cloud object storage, whereas volumes focus on governed, secure, and organized file storage under Unity Catalog. DBFS is the access mechanism used by the runtime, while volumes are the authoritative storage objects that control security and metadata. For new production workloads, Databricks recommends using Unity Catalog volumes instead of DBFS mounts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "bc2bad58-a764-4fda-85ab-17068dd14a3c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "###Volume vs DBFS / FileStore\n",
    "\n",
    "###DBFS \n",
    "FileStore is a filesystem abstraction layer provided by Databricks that allows clusters to interact with cloud object storage using Unix-like paths (dbfs:/, /dbfs/). FileStore is a DBFS-backed location mainly intended for temporary files, UI uploads, and notebooks. DBFS provides convenience and backward compatibility but does not offer governance, fine-grained access control, auditing, or lineage, making it unsuitable for production-grade systems.\n",
    "\n",
    "###Volumes\n",
    " are Unity Catalog–governed storage objects designed for storing non-tabular data in production environments. Volumes provide enterprise-grade features such as fine-grained access control (GRANT/REVOKE), auditing, lineage, and centralized credential management. Volumes are organized under catalogs and schemas, enabling consistent data governance across teams. Although volume paths may appear as dbfs:/Volumes/..., DBFS is only the runtime access layer, while Unity Catalog enforces all security and governance rules.\n",
    "\n",
    "###Why volumes are preferred for production-ready systems:\n",
    "Volumes enable secure, auditable, and governed access to files, align with enterprise data governance standards, support multi-team environments, and eliminate credential sprawl, making them the recommended approach for all new production workloads."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "26d8bd3d-b575-448b-ae22-8173d15ca671",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##Data files to use in this usecase:\n",
    "customer_csv = '''\n",
    "101,Arun,31,Chennai,PREPAID\n",
    "102,Meera,45,Bangalore,POSTPAID\n",
    "103,Irfan,29,Hyderabad,PREPAID\n",
    "104,Raj,52,Mumbai,POSTPAID\n",
    "105,,27,Delhi,PREPAID\n",
    "106,Sneha,abc,Pune,PREPAID\n",
    "'''\n",
    "\n",
    "usage_tsv = '''customer_id\\tvoice_mins\\tdata_mb\\tsms_count\n",
    "101\\t320\\t1500\\t20\n",
    "102\\t120\\t4000\\t5\n",
    "103\\t540\\t600\\t52\n",
    "104\\t45\\t200\\t2\n",
    "105\\t0\\t0\\t0\n",
    "'''\n",
    "\n",
    "tower_logs_region1 = '''event_id|customer_id|tower_id|signal_strength|timestamp\n",
    "5001|101|TWR01|-80|2025-01-10 10:21:54\n",
    "5004|104|TWR05|-75|2025-01-10 11:01:12\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9540d2e2-2562-4be7-897f-0a7d57adaa72",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##2. Filesystem operations\n",
    "1. Write code to copy the above datasets into your created Volume folders:\n",
    "Customer → /Volumes/.../customer/\n",
    "Usage → /Volumes/.../usage/\n",
    "Tower (region-based) → /Volumes/.../tower/region1/ and /Volumes/.../tower/region2/\n",
    "\n",
    "2. Write a command to validate whether files were successfully copied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c25321e9-1810-4d80-8c78-8911bbd02f26",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "customer_data = '''\n",
    "101,Arun,31,Chennai,PREPAID\n",
    "102,Meera,45,Bangalore,POSTPAID\n",
    "103,Irfan,29,Hyderabad,PREPAID\n",
    "104,Raj,52,Mumbai,POSTPAID\n",
    "105,,27,Delhi,PREPAID\n",
    "106,Sneha,abc,Pune,PREPAID\n",
    "'''\n",
    "dbutils.fs.put(f\"{cust_path}/customer_csv.csv\", customer_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "887f3106-0beb-4ec9-9af6-4cf4c49225a3",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "usage_data = '''customer_id\\tvoice_mins\\tdata_mb\\tsms_count\n",
    "101\\t320\\t1500\\t20\n",
    "102\\t120\\t4000\\t5\n",
    "103\\t540\\t600\\t52\n",
    "104\\t45\\t200\\t2\n",
    "105\\t0\\t0\\t0\n",
    "'''\n",
    "dbutils.fs.put(f\"{usage_path}/usage_csv.csv\", usage_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ab6124a9-0610-4a4a-98d0-a82fc974b4e7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_region1_ericsson_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5001|101|TWR01|-80|region1|ericsson|2025-01-10 10:21:54\n",
    "5002|104|TWR05|-75|region1|ericsson|2025-01-10 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region1/ericsson/tower_region1_ericsson.csv\", tower_region1_ericsson_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e68027ab-890c-459f-8cb6-e7673eab804f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_region1_nokia_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5003|106|TWR06|-45|region1|nokia|2025-01-10 10:21:54\n",
    "5004|107|TWR07|-55|region1|nokia|2025-01-10 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region1/nokia/tower_region1_nokia.csv\", tower_region1_nokia_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5a204a7f-f019-40e9-a37e-9432840975ad",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_region1_huawei_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5005|108|TWR08|-66|region1|huawei|2025-01-13 10:21:54\n",
    "5006|109|TWR09|-76|region1|huawei|2025-01-10 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region1/huawei/tower_region1_huawei.csv\", tower_region1_huawei_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ebefe0bd-044d-4952-ad3d-31e3cf67c56e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "tower_region2_ericsson_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5007|111|TWR10|-10|region2|ericsson|2025-01-19 10:21:54\n",
    "5008|112|TWR11|-73|region2|ericsson|2025-01-18 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region2/ericsson/tower_region2_ericsson.csv\", tower_region2_ericsson_data,overwrite = True)\n",
    "\n",
    "tower_region2_nokia_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5009|113|TWR16|-80|region2|nokia|2025-01-20 10:21:54\n",
    "5010|117|TWR15|-75|region2|nokia|2025-01-28 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region2/nokia/tower_region2_nokia.csv\", tower_region2_nokia_data,overwrite = True)\n",
    "\n",
    "tower_region2_huawei_data ='''event_id|customer_id|tower_id|signal_strength|region|vendor|timestamp\n",
    "5011|118|TWR06|-10|region2|huawei|2025-01-20 10:21:54\n",
    "5012|119|TWR05|-15|region2|huawei|2025-01-10 11:01:12\n",
    "'''\n",
    "dbutils.fs.put(f\"{tower_path}/region2/huawei/tower_region2_huawei.csv\", tower_region2_huawei_data,overwrite = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8767735b-24d3-428a-ad12-ae821903e2ce",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##3. Directory Read Use Cases\n",
    "1. Read all tower logs using:\n",
    "Path glob filter (example: *.csv)\n",
    "Multiple paths input\n",
    "Recursive lookup\n",
    "\n",
    "2. Demonstrate these 3 reads separately:\n",
    "Using pathGlobFilter\n",
    "Using list of paths in spark.read.csv([path1, path2])\n",
    "Using .option(\"recursiveFileLookup\",\"true\")\n",
    "\n",
    "3. Compare the outputs and understand when each should be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a78e8cf-ba06-4d9c-89ca-395c32656b7c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#1.Read all tower logs using: Path glob filter (example: *.csv) Multiple paths input Recursive lookup\n",
    "#print(spark)\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark1 = SparkSession.builder.getOrCreate()\n",
    "#print(spark1)\n",
    "df_tower_recursive = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"recursiveFileLookup\", \"true\")\n",
    "         .option(\"pathGlobFilter\", \"*.csv\")\n",
    "         .option(\"header\", True)\n",
    "         .option(\"sep\" , '|')\n",
    "         .load(tower_path)\n",
    ")\n",
    "display(df_tower_recursive)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f0c99686-a473-4779-81d7-7875b9bb5d17",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Reading from mulitple path\n",
    "df_tower_multi_path = (\n",
    "    spark.read\n",
    "         .csv(path = [f\"{tower_path}/region2/huawei/tower_region1_huawei.csv\",f\"{tower_path}/region2/nokia/tower_region2_nokia.csv\"], header = True, inferSchema = True, sep = \"|\")\n",
    ")\n",
    "display(df_tower_multi_path)\n",
    "\n",
    "#Reading using recursive option\n",
    "from pyspark.sql.session import SparkSession\n",
    "spark1 = SparkSession.builder.getOrCreate()\n",
    "#print(spark1)\n",
    "df_tower_recursive_alone = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .option(\"recursiveFileLookup\", \"true\")\n",
    "         .option(\"header\", True)\n",
    "         .option(\"sep\" , '|')\n",
    "         .load(f\"{tower_path}/region1\")\n",
    ")\n",
    "display(df_tower_recursive_alone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9f7147c1-5d58-47e1-84fe-7ebd26a217b9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##4. Schema Inference, Header, and Separator\n",
    "1. Try the Customer, Usage files with the option and options using read.csv and format function:<br>\n",
    "header=false, inferSchema=false<br>\n",
    "or<br>\n",
    "header=true, inferSchema=true<br>\n",
    "2. Write a note on What changed when we use header or inferSchema  with true/false?<br>\n",
    "3. How schema inference handled “abc” in age?<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "cffa7bee-2798-4c7b-9be1-014f0378cb96",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "df_customer_allfalse = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer_csv.csv\", header = False, inferSchema = False)\n",
    "df_usage_allfalse = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage_csv.csv\", header = False, inferSchema = False, sep = '\\t')\n",
    "df_customer_alltrue = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer_csv.csv\", header = True, inferSchema = True)\n",
    "df_usage_alltrue = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage_csv.csv\", header = True, inferSchema = True , sep = '\\t')\n",
    "\n",
    "display(df_customer_allfalse)\n",
    "display(df_customer_alltrue)\n",
    "display(df_usage_allfalse)\n",
    "display(df_usage_alltrue)\n",
    "df_customer_alltrue.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "15d8dad0-bc63-47f1-9a90-72837cba6c4f",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##5. Column Renaming Usecases\n",
    "1. Apply column names using string using toDF function for customer data\n",
    "2. Apply column names and datatype using the schema function for usage data\n",
    "3. Apply column names and datatype using the StructType with IntegerType, StringType, TimestampType and other classes for towers data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1a1dc933-bc3a-4ae0-be60-6e96ad3d79aa",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import StructType, IntegerType, StringType, StructField, TimestampType\n",
    "df_customer_cols = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer_csv.csv\").toDF(\"cust_id\",\"cust_name\",\"age\",\"city\",\"plan\")\n",
    "\n",
    "schema = \"cust_id integer, voice_mins float,data_mb integer, sms_count integer\"\n",
    "\n",
    "df_usage_cols = spark.read.schema(schema).csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/usage/usage_csv.csv\",sep = '\\t')\n",
    "\n",
    "schema_struct_cust = StructType([StructField(\"cust_id\", IntegerType(), False), StructField(\"cust_name\", StringType(), True), StructField(\"age\", IntegerType(), True), StructField(\"cust_city\", StringType(), True), StructField(\"cust_plan\", StringType(), True)])\n",
    "\n",
    "df_customer_struct = spark.read.csv(\"/Volumes/telecom_catalog_assign/landing_zone/landing_vol/customer/customer_csv.csv\", schema = schema_struct_cust)\n",
    "\n",
    "schema_struct_tower = StructType([StructField(\"event_id\", IntegerType(), True), StructField(\"cust_id\", IntegerType(), True), StructField(\"tower_id\", StringType(), True), StructField(\"sig_strngth\", IntegerType(), True), StructField(\"region\", StringType(), True), StructField(\"vendor\", StringType(), True), StructField(\"signal_ts\", TimestampType(), True)])\n",
    "\n",
    "\n",
    "df_struct_tower = df_tower_recursive = (\n",
    "    spark.read\n",
    "         .format(\"csv\")\n",
    "         .schema(schema_struct_tower)\n",
    "         .option(\"recursiveFileLookup\", \"true\")\n",
    "         .option(\"pathGlobFilter\", \"*.csv\")\n",
    "         .option(\"header\", True)\n",
    "         .option(\"sep\" , '|')\n",
    "         .load(tower_path)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "display(df_customer_cols)\n",
    "display(df_usage_cols)\n",
    "display(df_customer_struct)\n",
    "display(df_struct_tower)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6e1d6d88-7bcc-4548-a0d1-15d37f6fc0be",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "## 6. More to come (stay motivated)...."
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 7731179537441710,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "read_write_usecases",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
