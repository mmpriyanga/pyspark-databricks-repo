{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2d6b31df-053f-484e-a748-f3c78d465fb7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DateType,StructField,StructType,TimestampType\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "schema = StructType(\n",
    "    [\n",
    "        StructField(\"min_date\", DateType()),\n",
    "        StructField(\"end_date\", TimestampType())\n",
    "    ]\n",
    ")\n",
    "\n",
    "df = spark.createDataFrame(\n",
    "    [(\"2025-12-06\", \"2025-12-08 07:17:57.37546\")], \n",
    "    [\"min_date\", \"end_date\"]\n",
    ").withColumn(\"min_date\", col(\"min_date\").cast(\"date\")) \\\n",
    " .withColumn(\"end_date\", col(\"end_date\").cast(\"timestamp\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "0877cf91-ef7c-4cb9-a486-5544c7199599",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "display(df)\n",
    "date_seq = df.select(\n",
    "    F.sequence(\n",
    "        F.to_date(F.col(\"min_date\")),\n",
    "        F.to_date(F.col(\"end_date\")),\n",
    "        F.expr(\"interval 1 DAY\")\n",
    "    ).alias(\"cal_date\")\n",
    ")\n",
    "\n",
    "date_seq = date_seq.select(F.explode(\"cal_date\"))\n",
    "\n",
    "\n",
    "display(date_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "c163e9be-0bc5-472c-b5b9-2297e593c1ab",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import functions as F\n",
    "F.col(\"min_date\").between(\n",
    "    F.date_add(F.col(\"end_date\"),-6), F.col(\"end_date\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "14d0723e-d7ee-4bf4-b850-6320870c4aca",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "project_workflow_examples",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
